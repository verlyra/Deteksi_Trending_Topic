{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57ed206",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Sastrawi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Import Stemmer dari Sastrawi\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSastrawi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mStemmer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mStemmerFactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StemmerFactory\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# --- KONFIGURASI ---\u001b[39;00m\n\u001b[32m     12\u001b[39m DB_CONFIG = {\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhost\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mroot\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtwitter\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     17\u001b[39m }\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'Sastrawi'"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# Import Stemmer dari Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'twitter'\n",
    "}\n",
    "# Nama tabel data utama\n",
    "TABLE_NAME = 'trending' \n",
    "ID_COLUMN = 'id'\n",
    "TEXT_COLUMN = 'isi_twit'\n",
    "\n",
    "# Nama tabel kamus slang\n",
    "SLANG_TABLE_NAME = 'slangword'\n",
    "SLANG_COLUMN = 'kata_tbaku'\n",
    "FORMAL_COLUMN = 'kata_baku'\n",
    "\n",
    "\n",
    "# Nama kolom untuk setiap langkah (ditambahkan langkah baru)\n",
    "STEP_COLUMNS = {\n",
    "    'lower': 'lowercase',\n",
    "    'no_punct': 'no_punctuation',\n",
    "    'tokenized': 'tokenized',\n",
    "    'no_stopwords': 'no_stopwords',\n",
    "    'no_slang': 'no_slang',\n",
    "    'stemmed': 'stemmed',\n",
    "    'final': 'final_processed_text'\n",
    "}\n",
    "\n",
    "# --- FUNGSI BARU UNTUK MEMUAT KAMUS SLANG DARI DB ---\n",
    "def load_slang_dictionary(conn):\n",
    "    \"\"\"\n",
    "    Mengambil data dari tabel kamus slang dan mengubahnya menjadi dictionary Python.\n",
    "    \"\"\"\n",
    "    slang_dict = {}\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        query = f\"SELECT {SLANG_COLUMN}, {FORMAL_COLUMN} FROM {SLANG_TABLE_NAME}\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Mengubah hasil query (list of tuples) menjadi dictionary\n",
    "        for row in rows:\n",
    "            slang, formal = row\n",
    "            if slang: # Pastikan kata slang tidak kosong\n",
    "                slang_dict[slang.strip()] = formal.strip()\n",
    "        \n",
    "        print(f\"Berhasil memuat {len(slang_dict)} kata dari kamus slang.\")\n",
    "        return slang_dict\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"Error saat memuat kamus slang: {e}\")\n",
    "        return {} # Kembalikan dictionary kosong jika gagal\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "# --- FUNGSI PRA-PEMROSESAN YANG DIPERBARUI ---\n",
    "# Sekarang fungsi ini memerlukan kamus slang sebagai argumen\n",
    "def process_and_get_steps(text, slang_dict, stemmer, stop_words_combined):\n",
    "    results = {}\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        # Mengembalikan nilai default kosong\n",
    "        for col in STEP_COLUMNS.values():\n",
    "            results[col] = '' if 'token' not in col else json.dumps([])\n",
    "        return results\n",
    "\n",
    "    # 1. Lowercase\n",
    "    lower_text = text.lower()\n",
    "    results[STEP_COLUMNS['lower']] = lower_text\n",
    "\n",
    "    # 2. Hapus Tanda Baca\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    no_punct_text = lower_text.translate(translator)\n",
    "    results[STEP_COLUMNS['no_punct']] = no_punct_text\n",
    "\n",
    "    # 3. Tokenisasi\n",
    "    tokens = word_tokenize(no_punct_text)\n",
    "    results[STEP_COLUMNS['tokenized']] = json.dumps(tokens)\n",
    "\n",
    "    # 4. Hapus Stopwords\n",
    "    no_stopwords_tokens = [word for word in tokens if word not in stop_words_combined and word.isalpha()]\n",
    "    results[STEP_COLUMNS['no_stopwords']] = json.dumps(no_stopwords_tokens)\n",
    "\n",
    "    # 5. Normalisasi Slang Word (menggunakan slang_dict dari argumen)\n",
    "    no_slang_tokens = [slang_dict.get(word, word) for word in no_stopwords_tokens]\n",
    "    results[STEP_COLUMNS['no_slang']] = json.dumps(no_slang_tokens)\n",
    "    \n",
    "    # 6. Stemming\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in no_slang_tokens]\n",
    "    results[STEP_COLUMNS['stemmed']] = json.dumps(stemmed_tokens)\n",
    "\n",
    "    # 7. Teks Final\n",
    "    final_text = ' '.join(stemmed_tokens)\n",
    "    results[STEP_COLUMNS['final']] = final_text\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --- FUNGSI DATABASE (SAMA SEPERTI SEBELUMNYA) ---\n",
    "def setup_database_columns(conn, table_name):\n",
    "    cursor = conn.cursor(buffered=True)\n",
    "    print(f\"Memeriksa struktur tabel '{table_name}'...\")\n",
    "    try:\n",
    "        cursor.execute(f\"DESCRIBE {table_name};\")\n",
    "        existing_columns = [col[0] for col in cursor.fetchall()]\n",
    "        \n",
    "        for col_name in STEP_COLUMNS.values():\n",
    "            if col_name not in existing_columns:\n",
    "                print(f\"Kolom '{col_name}' tidak ditemukan. Menambahkan...\")\n",
    "                cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {col_name} TEXT NULL\")\n",
    "                print(f\"Kolom '{col_name}' berhasil ditambahkan.\")\n",
    "        conn.commit()\n",
    "    except Error as e:\n",
    "        print(f\"Error saat setup kolom: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# --- FUNGSI UTAMA YANG DIPERBARUI ---\n",
    "def main():\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**DB_CONFIG)\n",
    "        if not conn.is_connected():\n",
    "            print(\"Gagal terhubung ke database.\")\n",
    "            return\n",
    "\n",
    "        print(\"Berhasil terhubung ke database MySQL.\")\n",
    "        \n",
    "        # INISIALISASI OBJECT PENTING (dilakukan sekali saja setelah koneksi berhasil)\n",
    "        # 1. Muat Kamus Slang dari DB\n",
    "        slang_dict = load_slang_dictionary(conn)\n",
    "        if not slang_dict:\n",
    "            print(\"Kamus slang kosong atau gagal dimuat. Proses dihentikan.\")\n",
    "            return\n",
    "\n",
    "        # 2. Buat Stemmer\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        # 3. Muat Stopwords\n",
    "        stop_words_id = set(stopwords.words('indonesian'))\n",
    "        stop_words_en = set(stopwords.words('english'))\n",
    "        stop_words_combined = stop_words_id.union(stop_words_en)\n",
    "\n",
    "        # Siapkan kolom-kolom di tabel data\n",
    "        setup_database_columns(conn, TABLE_NAME)\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = f\"SELECT {ID_COLUMN}, {TEXT_COLUMN} FROM {TABLE_NAME} WHERE {TEXT_COLUMN} IS NOT NULL AND {STEP_COLUMNS['final']} IS NULL\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if not rows:\n",
    "            print(\"Tidak ada data baru untuk diproses.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Ditemukan {len(rows)} baris data baru untuk diproses.\")\n",
    "        \n",
    "        update_data = []\n",
    "        for row in rows:\n",
    "            tweet_id, original_text = row\n",
    "            # Kirim object yang diperlukan ke fungsi proses\n",
    "            processed_steps = process_and_get_steps(original_text, slang_dict, stemmer, stop_words_combined)\n",
    "            \n",
    "            update_values = (\n",
    "                processed_steps[STEP_COLUMNS['lower']], processed_steps[STEP_COLUMNS['no_punct']],\n",
    "                processed_steps[STEP_COLUMNS['tokenized']], processed_steps[STEP_COLUMNS['no_stopwords']],\n",
    "                processed_steps[STEP_COLUMNS['no_slang']], processed_steps[STEP_COLUMNS['stemmed']],\n",
    "                processed_steps[STEP_COLUMNS['final']], tweet_id\n",
    "            )\n",
    "            update_data.append(update_values)\n",
    "        \n",
    "        if update_data:\n",
    "            print(\"Menyimpan hasil ke database...\")\n",
    "            update_query = f\"\"\"\n",
    "                UPDATE {TABLE_NAME} SET \n",
    "                    {STEP_COLUMNS['lower']} = %s, {STEP_COLUMNS['no_punct']} = %s,\n",
    "                    {STEP_COLUMNS['tokenized']} = %s, {STEP_COLUMNS['no_stopwords']} = %s,\n",
    "                    {STEP_COLUMNS['no_slang']} = %s, {STEP_COLUMNS['stemmed']} = %s,\n",
    "                    {STEP_COLUMNS['final']} = %s\n",
    "                WHERE {ID_COLUMN} = %s\n",
    "            \"\"\"\n",
    "            cursor.executemany(update_query, update_data)\n",
    "            conn.commit()\n",
    "            print(f\"{cursor.rowcount} baris berhasil diperbarui di database.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error pada fungsi utama: {e}\")\n",
    "    finally:\n",
    "        if conn and conn.is_connected():\n",
    "            conn.close()\n",
    "            print(\"Koneksi MySQL ditutup.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Pastikan resource NLTK 'punkt' dan 'stopwords' sudah diunduh\n",
    "    for package in ['punkt', 'stopwords']:\n",
    "        try:\n",
    "            nltk.data.find(f'tokenizers/{package}' if package == 'punkt' else f'corpora/{package}')\n",
    "        except LookupError:\n",
    "            print(f\"Corpus '{package}' tidak ditemukan. Mengunduh...\")\n",
    "            nltk.download(package)\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
