{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee7a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource NLTK 'stopwords' tidak ditemukan. Mengunduh...\n",
      "Resource NLTK 'punkt_tab' tidak ditemukan. Mengunduh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil terhubung ke database MySQL.\n",
      "Memeriksa struktur tabel...\n",
      "Ditemukan 80 baris data baru untuk diproses.\n",
      "Menyimpan hasil ke database...\n",
      "80 baris berhasil diperbarui di database.\n",
      "Koneksi MySQL ditutup.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import string\n",
    "import json  # Import library JSON untuk menyimpan list sebagai string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Ganti dengan detail koneksi database MySQL Anda\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'twitter'\n",
    "}\n",
    "\n",
    "# Ganti dengan nama tabel dan kolom Anda\n",
    "TABLE_NAME = 'trending' # GANTI INI\n",
    "ID_COLUMN = 'id'\n",
    "TEXT_COLUMN = 'isi_twit'\n",
    "\n",
    "# Nama kolom untuk setiap langkah\n",
    "STEP_COLUMNS = {\n",
    "    'lower': 'lowercase',\n",
    "    'no_punct': 'no_punctuation',\n",
    "    'tokenized': 'tokenized',\n",
    "    'no_stopwords': 'no_stopwords',\n",
    "    'final': 'final_processed_text'\n",
    "}\n",
    "\n",
    "# --- FUNGSI PRA-PEMROSESAN ---\n",
    "# Memuat stop words sekali saja untuk efisiensi\n",
    "try:\n",
    "    stop_words_id = set(stopwords.words('indonesian'))\n",
    "    stop_words_en = set(stopwords.words('english'))\n",
    "    stop_words_combined = stop_words_id.union(stop_words_en)\n",
    "except LookupError:\n",
    "    print(\"Stopwords corpus tidak ditemukan. Mengunduh...\")\n",
    "    nltk.download('stopwords')\n",
    "    stop_words_id = set(stopwords.words('indonesian'))\n",
    "    stop_words_en = set(stopwords.words('english'))\n",
    "    stop_words_combined = stop_words_id.union(stop_words_en)\n",
    "\n",
    "\n",
    "def process_and_get_steps(text):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan pra-pemrosesan dan mengembalikan hasil setiap langkah dalam dictionary.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Handle jika teks kosong atau bukan string\n",
    "    if not isinstance(text, str):\n",
    "        # Mengembalikan nilai default kosong untuk setiap langkah\n",
    "        results[STEP_COLUMNS['lower']] = ''\n",
    "        results[STEP_COLUMNS['no_punct']] = ''\n",
    "        results[STEP_COLUMNS['tokenized']] = json.dumps([])\n",
    "        results[STEP_COLUMNS['no_stopwords']] = json.dumps([])\n",
    "        results[STEP_COLUMNS['final']] = ''\n",
    "        return results\n",
    "\n",
    "    # 1. Mengubah teks ke huruf kecil\n",
    "    lower_text = text.lower()\n",
    "    results[STEP_COLUMNS['lower']] = lower_text\n",
    "\n",
    "    # 2. Menghapus tanda baca\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    no_punct_text = lower_text.translate(translator)\n",
    "    results[STEP_COLUMNS['no_punct']] = no_punct_text\n",
    "\n",
    "    # 3. Tokenisasi kata\n",
    "    tokens = word_tokenize(no_punct_text)\n",
    "    # Simpan sebagai string JSON agar bisa disimpan di kolom TEXT\n",
    "    results[STEP_COLUMNS['tokenized']] = json.dumps(tokens)\n",
    "\n",
    "    # 4. Stop words removal\n",
    "    clean_tokens = [word for word in tokens if word not in stop_words_combined and word.isalpha()]\n",
    "    results[STEP_COLUMNS['no_stopwords']] = json.dumps(clean_tokens)\n",
    "\n",
    "    # 5. Membuat string final yang sudah bersih\n",
    "    final_text = ' '.join(clean_tokens)\n",
    "    results[STEP_COLUMNS['final']] = final_text\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --- FUNGSI DATABASE ---\n",
    "def setup_database_columns(conn):\n",
    "    \"\"\"Memeriksa dan menambahkan kolom yang diperlukan jika belum ada.\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Memeriksa struktur tabel...\")\n",
    "    try:\n",
    "        for col_name in STEP_COLUMNS.values():\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT COUNT(*) FROM information_schema.COLUMNS \n",
    "                WHERE TABLE_SCHEMA = '{DB_CONFIG['database']}' \n",
    "                AND TABLE_NAME = '{TABLE_NAME}' \n",
    "                AND COLUMN_NAME = '{col_name}'\n",
    "            \"\"\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(f\"Kolom '{col_name}' tidak ditemukan. Menambahkan...\")\n",
    "                cursor.execute(f\"ALTER TABLE {TABLE_NAME} ADD COLUMN {col_name} TEXT NULL\")\n",
    "                print(f\"Kolom '{col_name}' berhasil ditambahkan.\")\n",
    "        conn.commit()\n",
    "    except Error as e:\n",
    "        print(f\"Error saat setup kolom: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# --- FUNGSI UTAMA ---\n",
    "def main():\n",
    "    \"\"\"Fungsi utama untuk menghubungkan ke DB, memproses, dan menyimpan kembali.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**DB_CONFIG)\n",
    "        \n",
    "        if conn.is_connected():\n",
    "            print(\"Berhasil terhubung ke database MySQL.\")\n",
    "            \n",
    "            # 1. Siapkan kolom-kolom di database\n",
    "            setup_database_columns(conn)\n",
    "\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # 2. Ambil data yang belum diproses (kita cek dari kolom final)\n",
    "            query = f\"\"\"\n",
    "                SELECT {ID_COLUMN}, {TEXT_COLUMN} \n",
    "                FROM {TABLE_NAME} \n",
    "                WHERE {TEXT_COLUMN} IS NOT NULL \n",
    "                AND {STEP_COLUMNS['final']} IS NULL\n",
    "            \"\"\"\n",
    "            cursor.execute(query)\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                print(\"Tidak ada data baru untuk diproses.\")\n",
    "                return\n",
    "\n",
    "            print(f\"Ditemukan {len(rows)} baris data baru untuk diproses.\")\n",
    "            \n",
    "            update_data = []\n",
    "\n",
    "            # 3. Proses setiap baris\n",
    "            for row in rows:\n",
    "                tweet_id, original_text = row\n",
    "                \n",
    "                # Panggil fungsi pra-pemrosesan\n",
    "                processed_steps = process_and_get_steps(original_text)\n",
    "                \n",
    "                # Siapkan data untuk update (pastikan urutannya benar)\n",
    "                update_values = (\n",
    "                    processed_steps[STEP_COLUMNS['lower']],\n",
    "                    processed_steps[STEP_COLUMNS['no_punct']],\n",
    "                    processed_steps[STEP_COLUMNS['tokenized']],\n",
    "                    processed_steps[STEP_COLUMNS['no_stopwords']],\n",
    "                    processed_steps[STEP_COLUMNS['final']],\n",
    "                    tweet_id # ID untuk klausa WHERE\n",
    "                )\n",
    "                update_data.append(update_values)\n",
    "\n",
    "            # 4. Simpan hasil kembali ke database menggunakan executemany (lebih cepat)\n",
    "            if update_data:\n",
    "                print(\"Menyimpan hasil ke database...\")\n",
    "                update_query = f\"\"\"\n",
    "                    UPDATE {TABLE_NAME} SET \n",
    "                        {STEP_COLUMNS['lower']} = %s,\n",
    "                        {STEP_COLUMNS['no_punct']} = %s,\n",
    "                        {STEP_COLUMNS['tokenized']} = %s,\n",
    "                        {STEP_COLUMNS['no_stopwords']} = %s,\n",
    "                        {STEP_COLUMNS['final']} = %s\n",
    "                    WHERE {ID_COLUMN} = %s\n",
    "                \"\"\"\n",
    "                cursor.executemany(update_query, update_data)\n",
    "                conn.commit()\n",
    "                print(f\"{cursor.rowcount} baris berhasil diperbarui di database.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error saat menghubungkan atau memproses data: {e}\")\n",
    "    finally:\n",
    "        if conn and conn.is_connected():\n",
    "            conn.close()\n",
    "            print(\"Koneksi MySQL ditutup.\")\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    # Memeriksa dan mengunduh resource NLTK yang diperlukan jika belum ada\n",
    "    required_packages = ['punkt', 'stopwords', 'punkt_tab']\n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            # Coba cari paketnya\n",
    "            nltk.data.find(f'tokenizers/{package.replace(\"_tab\", \"\")}')\n",
    "            if package == 'punkt_tab': # Pengecekan khusus untuk punkt_tab\n",
    "                nltk.data.find('tokenizers/punkt_tab/english')\n",
    "        except LookupError:\n",
    "            # Jika tidak ditemukan, unduh\n",
    "            print(f\"Resource NLTK '{package}' tidak ditemukan. Mengunduh...\")\n",
    "            nltk.download(package)\n",
    "    \n",
    "    # Setelah semua paket dipastikan ada, jalankan fungsi utama\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
